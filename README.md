# Machine Learning Experiments: Decision Trees, Logistic Regression & SVM ğŸ“Š

## Overview ğŸ“Œ
This repository contains **three machine learning projects**, focusing on classification techniques and model optimization. The projects explore **decision trees, logistic regression, and support vector machines (SVM)** in different contexts, including **hyperparameter tuning and credit risk prediction**.

## Objectives ğŸ¯
- Optimize **decision tree depth, splitting criteria, and regularization**.
- Analyze the impact of **regularization in logistic regression and SVM**.
- Build a **predictive model for credit risk assessment** using machine learning.

## Projects & Implementations ğŸ› ï¸
### **1ï¸âƒ£ Decision Tree Optimization** ğŸŒ³
- Comparison of tree depth and **overfitting vs. generalization**.
- Tuning **Gini impurity vs. entropy** as splitting criteria.
- Regularization techniques (**minimum samples per split, pruning**).
- Evaluation using **cross-validation and accuracy metrics**.

### **2ï¸âƒ£ Logistic Regression & SVM Classification** ğŸ“ˆ
- Implementing **logistic regression with L1 and L2 regularization**.
- Optimizing **hyperparameters (C, kernel types for SVM)**.
- Comparing **logistic regression vs. SVM in classification tasks**.
- Using **precision, recall, and F1-score** for model evaluation.

### **3ï¸âƒ£ Credit Risk Prediction Model** ğŸ’³
- Predicting **credit default risk** using financial data.
- Handling **imbalanced data** with undersampling and oversampling.
- Feature engineering for **improving model performance**.
- Evaluating **balanced accuracy** as the key metric.


## Key Insights ğŸ”
âœ… **Decision tree depth significantly affects overfitting**.  
âœ… **L2 regularization in logistic regression improves stability**.  
âœ… **SVM with RBF kernel performs well on non-linearly separable data**.  
âœ… **Balanced accuracy is a better metric for credit risk classification than simple accuracy**.  

## License ğŸ“„
This project is licensed under the **MIT License** â€“ see the `LICENSE` file for details.

---
### ğŸš€ Exploring ML techniques for better predictive modeling!

